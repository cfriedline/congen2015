{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import rpy2\n",
    "from rpy2 import robjects as ro\n",
    "import pandas.rpy.common as com\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import operator\n",
    "import scipy as sp\n",
    "import traceback\n",
    "from sklearn import preprocessing\n",
    "from IPython.parallel import Client\n",
    "from subprocess import Popen, PIPE\n",
    "import shutil\n",
    "from IPython.display import FileLink, FileLinks, Image\n",
    "import psutil\n",
    "import multiprocessing\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext rpy2.ipython\n",
    "pd.set_option('display.width', 80)\n",
    "pd.set_option('max.columns', 30)\n",
    "\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "R.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_ai = pd.read_excel(\"/gdc_home4/cfried/landscape_genetics_data/Genetics_2010/Eckert_Genetics_2010_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ai_cols = ['AI_Q1','AI_Q2','AI_Q3','AI_Q4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_gt = pd.read_excel(\"/gdc_home4/cfried/landscape_genetics_data/Genetics_2010/Eckert_Genetics_2010_data.xlsx\", \n",
    "                        sheetname=\"genotyping_data\")\n",
    "\n",
    "data_loc = pd.read_excel(\"/gdc_home4/cfried/landscape_genetics_data/Genetics_2010/Eckert_Genetics_2010_data.xlsx\",\n",
    "                         sheetname=\"county_locality\")\n",
    "\n",
    "results = pd.read_excel(\"/gdc_home4/cfried/landscape_genetics_data/Genetics_2010/Eckert_Genetics_2010_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trait_name = \"sucrose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pheno = pd.read_excel(\"/gdc_home4/cfried/landscape_genetics_data/Pinus_taeda_metabolite_data.xlsx\", \n",
    "                      sheetname=\"metabolite_phenotype_data\",\n",
    "                      header=2)\n",
    "pheno = pheno[['Longitude', 'Latitude','Clone_id',trait_name]]\n",
    "\n",
    "pheno.index = pheno.Clone_id\n",
    "#pheno = pheno.drop('Clone_id', axis=1)\n",
    "pheno[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_phenotype(row):\n",
    "    return np.max(pheno[(pheno.Longitude==row.long) & (pheno.Latitude==row.lat)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_gt[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results.index = results.locus\n",
    "results = results.drop(\"locus\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genotypes = data_gt.ix[:,[x for x in data_gt.columns if '-' in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genotypes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genotypes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_homozygous(gt):\n",
    "    if len(set([x.strip() for x in gt.split(\"/\")])) == 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_allele_counts(counts):\n",
    "    a = {}\n",
    "    het = 0\n",
    "    for gt in counts.index:\n",
    "        for allele in [x.strip() for x in gt.split(\"/\")]:\n",
    "            if not allele in a:\n",
    "                a[allele] = 0\n",
    "            a[allele] += counts[gt]\n",
    "        if not is_homozygous(gt):\n",
    "            het += counts[gt]\n",
    "    return sorted(a.items(), key=lambda x: x[1], reverse=True), het\n",
    "\n",
    "def get_correction(n):\n",
    "    #for finite sample size\n",
    "    return (2*n)/(2*n-1)\n",
    "\n",
    "def get_allele_freqs(locus):\n",
    "    locus = locus[locus != '?/?']\n",
    "    locus = locus[locus != 'NA']\n",
    "    c = locus.value_counts()\n",
    "    c = c.sort(inplace=False, ascending=False)\n",
    "    allele_counts = get_allele_counts(c)\n",
    "    total_alleles = 2.0*sum(c)\n",
    "    num_individuals = sum(c)\n",
    "    A = \"\"\n",
    "    a = \"\"\n",
    "    P = 0\n",
    "    Q = 0\n",
    "    if len(allele_counts[0]) == 2:\n",
    "        A = allele_counts[0][0][0]\n",
    "        a = allele_counts[0][1][0]\n",
    "        P = allele_counts[0][0][1]\n",
    "        Q = allele_counts[0][1][1]\n",
    "    else:\n",
    "        A = allele_counts[0][0][0]\n",
    "        P = P = allele_counts[0][0][1]\n",
    "    PQ = allele_counts[-1]\n",
    "    p = P/total_alleles\n",
    "    q = Q/total_alleles\n",
    "    assert p + q == 1.0\n",
    "    He = 2 * p * q * get_correction(num_individuals)\n",
    "    Ho = PQ*1.0/num_individuals\n",
    "    Fis = 1 - (Ho/He)\n",
    "    #print p, q, He, Ho, Fis\n",
    "    ret = pd.Series({\"p\":p, \n",
    "                      \"q\":q,\n",
    "                      \"P\":P,\n",
    "                      \"Q\":Q,\n",
    "                      \"He\":He,\n",
    "                      \"Ho\":Ho, \n",
    "                      \"Fis\":Fis,\n",
    "                    \"PQ\": PQ,\n",
    "                    \"total_alleles\":total_alleles,\n",
    "                    \"num_indiv\":num_individuals,\n",
    "                    \"A\":A,\n",
    "                    \"a\":a})\n",
    "    return ret\n",
    "#genotypes.ix[:,0:2].apply(get_allele_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "af = genotypes.apply(get_allele_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "af.ix[:,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_hist(df, index):\n",
    "    d = df.ix[index,:]\n",
    "    plt.hist(d, bins=20)\n",
    "    plt.title(\"%s %.2f $\\pm$ %.3f [%.2f, %.2f]\" % (index, \n",
    "                                                   np.mean(d), \n",
    "                                                   np.std(d),\n",
    "                                                  np.min(d),\n",
    "                                                  np.max(d)))\n",
    "    plt.show()\n",
    "plot_hist(af, \"Fis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_z12(locus):\n",
    "    freq = af[locus.name]\n",
    "    trans = {\"%s/%s\" % (freq[\"A\"],freq[\"A\"]): 0,\n",
    "            \"%s/%s\" % (freq[\"a\"],freq[\"a\"]): 2,\n",
    "            \"%s/%s\" % (freq[\"A\"],freq[\"a\"]): 1,\n",
    "            \"%s/%s\" % (freq[\"a\"],freq[\"A\"]): 1,\n",
    "            \"?/?\":-1}\n",
    "    return locus.apply(lambda x: trans[x])\n",
    "z12 = genotypes.apply(convert_to_z12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def center_and_standardize_value(val, u, var):\n",
    "    if val == -1:\n",
    "        return 0.0\n",
    "    return (val-u)/np.sqrt(var)\n",
    "\n",
    "def center_and_standardize(snp):\n",
    "    maf = af.ix[\"q\",snp.name]\n",
    "    u = np.mean([x for x in snp if x != -1])\n",
    "    var = np.sqrt(maf*(1-maf))\n",
    "    return snp.apply(center_and_standardize_value, args=(u, var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std = z12.apply(center_and_standardize)\n",
    "pca_std.apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = ro.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prcomp = r('prcomp')\n",
    "summary = r('summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prcomp_res = prcomp(pca_std, scale=False, center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print summary(prcomp_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = com.convert_robj(prcomp_res.rx2(\"x\"))\n",
    "x.index = pca_std.index\n",
    "x.ix[0:5,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(x.PC1, x.PC2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "source(\"tw_calc.R\")\n",
    "test=read.table(\"twtable\", header=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TWcalc = r('TWcalc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw = TWcalc(com.convert_to_r_matrix(pca_std), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw_p = com.convert_robj(tw.rx2(2))\n",
    "tw_e = com.convert_robj(tw.rx2(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw_num = 0\n",
    "for i, p in enumerate(tw_p):\n",
    "    print i, p\n",
    "    if p > 0.05:\n",
    "        tw_num = i\n",
    "        break\n",
    "print \"Tracy-Widom test yields %d axes of pop structure\" % tw_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = pd.DataFrame(x)\n",
    "for col in y.columns[0:10]:\n",
    "    s_cutoff = np.std(y[col])*6\n",
    "    u = np.mean(y[col])\n",
    "    cutoff = sorted([u+s_cutoff, u-s_cutoff], reverse=True)\n",
    "    outliers = y[col][(y[col] > cutoff[0]) | (y[col] < cutoff[1])]\n",
    "    print col\n",
    "    print outliers\n",
    "    y = y.drop(outliers.index)\n",
    "y.ix[0:5,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_drop = genotypes.ix[y.index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_drop[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gt_drop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_drop = gt_drop.apply(convert_to_z12)\n",
    "z12_drop[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_drop_std = z12_drop.apply(center_and_standardize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_drop_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_drop_std[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_drop_std.describe().ix[:,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prcomp_res_drop = prcomp(pca_drop_std, scale=False, center=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_drop = com.convert_robj(prcomp_res_drop.rx2(\"x\"))\n",
    "x_drop.index = pca_drop_std.index\n",
    "x_drop.ix[0:5,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(x_drop.PC1, x_drop.PC2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print summary(prcomp_res_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw = TWcalc(com.convert_to_r_matrix(pca_drop_std), 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tw_p = com.convert_robj(tw.rx2(2))\n",
    "tw_e = com.convert_robj(tw.rx2(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw_num = 0\n",
    "for i, p in enumerate(tw_p):\n",
    "    print i, p\n",
    "    if p > 0.05:\n",
    "        tw_num = i\n",
    "        break\n",
    "print \"Tracy-Widom test yields %d axes of pop structure\" % tw_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hierf_trans = {0:11, 1:12, 2:22, -1:'NA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_hierf_trans(series):\n",
    "    return [hierf_trans[x] if x in hierf_trans else x for x in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_df = z12_drop.apply(apply_hierf_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hierf_df.insert(0, \"countyid\", None)\n",
    "hierf_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_hierf = data_loc.join(hierf_df, how=\"inner\")\n",
    "bayenv_df = loc_hierf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print hierf_df.shape, data_loc.shape, loc_hierf.shape, bayenv_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_hierf['county_state'] = loc_hierf.apply(lambda row: \"%s_%s\" % (row.county, row.state), axis=1)\n",
    "usable_counties = set()\n",
    "county_counts = loc_hierf.county_state.value_counts()\n",
    "county_counts = county_counts.sort(inplace=False, ascending=False)\n",
    "for c in county_counts.index:\n",
    "    print c, county_counts[c]\n",
    "for c in county_counts.index:\n",
    "    if county_counts[c] >=5:\n",
    "        usable_counties.add(c)\n",
    "usable_counties = sorted(list(usable_counties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "county_id = {}\n",
    "for i, county in enumerate(usable_counties):\n",
    "    county_id[county] = i+1\n",
    "county_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_hierf['usable'] = loc_hierf.apply(lambda row: row.county_state in county_id, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop = loc_hierf[loc_hierf.usable==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_hierf = loc_hierf.drop(drop.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_hierf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_hierf['countyid'] = loc_hierf.apply(lambda row: county_id[row.county_state], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_hierf[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_hierf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sorted(loc_hierf.countyid.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc_hierf.ix[:,4:-2].to_csv(\"hierf.txt\", sep=\"\\t\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "# library(hierfstat)\n",
    "# data = read.table(\"hierf.txt\", header=T, sep=\"\\t\")\n",
    "# data = data[order(data$countyid),]\n",
    "# levels = data.frame(data$countyid)\n",
    "# loci = data[,2:ncol(data)]\n",
    "# bs = basic.stats(data)\n",
    "# saveRDS(bs, \"basic_stats.rds\")\n",
    "# res = varcomp.glob(levels=levels, loci=loci, diploid=T)\n",
    "# saveRDS(res, \"hierf.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "bs = readRDS(\"basic_stats.rds\")\n",
    "res = readRDS(\"hierf.rds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = com.convert_robj(ro.r('res'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bs = com.convert_robj(ro.r('bs'))\n",
    "Fis = bs['Fis']\n",
    "Hs = bs['Hs']\n",
    "pop_freq_temp = bs['pop.freq']\n",
    "pop_freq = {}\n",
    "perloc = bs['perloc']\n",
    "n_ind_samp = bs['n.ind.samp']\n",
    "Ho = bs['Ho']\n",
    "overall = bs['overall']\n",
    "\n",
    "for df in [Fis, Hs, perloc, n_ind_samp, Ho]:\n",
    "    df.index = [x[1:].replace(\".\",\"-\") for x in df.index]\n",
    "\n",
    "for locus, data in pop_freq_temp.items():\n",
    "    if len(data) == 2:\n",
    "        data.index = ['p','q']\n",
    "    else:\n",
    "        data.index = ['p']\n",
    "    pop_freq[locus[1:].replace(\".\", \"-\")] = data\n",
    "\n",
    "Ho = Ho.T\n",
    "perloc = perloc.T\n",
    "n_ind_samp = n_ind_samp.T\n",
    "Hs = Hs.T\n",
    "Fis = Fis.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perloc['0-10037-01-257']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "af['0-10037-01-257']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_df = res['loc']\n",
    "F_df = res['F']\n",
    "overall_df = res['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_fst(series):\n",
    "    Va = series[0]\n",
    "    Vt = sum(series)\n",
    "    return Va/Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_fst = loc_df.apply(compute_fst, axis=1).dropna()\n",
    "loci_fst.index = [x[1:].replace(\".\", \"-\") for x in loci_fst.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(loci_fst, bins=50)\n",
    "plt.xlim(-.03, .5)\n",
    "plt.title(\"Fst for %d loci ($\\mu=%.3f \\pm %.4f$) [%.3f, %.3f]\" % (len(loci_fst),\n",
    "                                                                  np.mean(loci_fst),\n",
    "                                                                  np.std(loci_fst),\n",
    "                                                                  np.min(loci_fst),\n",
    "                                                                  np.max(loci_fst)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loc_hierf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait = loc_hierf.apply(get_phenotype, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait_loc_hierf = trait.join(loc_hierf, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait_complete = trait_loc_hierf.drop(trait_loc_hierf[np.isnan(trait_loc_hierf[trait_name])].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait_complete[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_snpassoc(col):\n",
    "    if \"-\" in col.name:\n",
    "        freqs = af[col.name]\n",
    "        trans = {11: \"%s/%s\" % (freqs[\"A\"], freqs[\"A\"]),\n",
    "                12: \"%s/%s\" % (freqs[\"A\"], freqs[\"a\"]),\n",
    "                22: \"%s/%s\" % (freqs[\"a\"], freqs[\"a\"]),\n",
    "                \"NA\":\"NA\"}\n",
    "        return col.apply(lambda x: trans[x])\n",
    "    return col\n",
    "trait_snpassoc = trait_complete.apply(convert_to_snpassoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_cov = x_drop.ix[:,0:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trait_snpassoc_pca = trait_snpassoc.join(pca_cov, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait_snpassoc_pca = trait_snpassoc_pca.drop(['county_state',\n",
    "                                                   'usable',\n",
    "                                                   'Longitude',\n",
    "                                                   'Latitude',\n",
    "                                                   'Clone_id',\n",
    "                                                   'county',\n",
    "                                                   'state',\n",
    "                                                   'lat',\n",
    "                                                   'long',\n",
    "                                                   'countyid'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait_snpassoc_pca[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait_snpassoc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trait_snpassoc_pca.to_csv(\"snpassoc.txt\",\n",
    "                             header=True,\n",
    "                             index=True,\n",
    "                             sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_snpassoc_file(df, input_file, num_pca_axes):\n",
    "    pheno = df.columns[0:1]\n",
    "    out_files = []\n",
    "    for p in pheno:\n",
    "        with open(\"snpassoc_%s.R\" % p.lower(), \"w\") as o:\n",
    "            print \"writing %s\" % o.name\n",
    "            out_files.append(o.name)\n",
    "            text = '''\n",
    "library(SNPassoc)\n",
    "\n",
    "d = read.table('%s', sep=\"\\\\t\", row.names=1, header=T)\n",
    "\n",
    "#subtract b/c those are the PCA axes\n",
    "snp_cols = 2:(ncol(d)-%d)\n",
    "snp_data = setupSNP(d, colSNPs=snp_cols, sep=\"/\")\n",
    "pca_cols = (ncol(d)-%d):ncol(d)\n",
    "pca_data = d[,pca_cols]\n",
    "\n",
    "wg = WGassociation(%s~1+pca_data$PC1+pca_data$PC2+pca_data$PC3+pca_data$PC4+\n",
    "pca_data$PC5+pca_data$PC6+pca_data$PC7+pca_data$PC8+pca_data$PC9+pca_data$PC10+\n",
    "+pca_data$PC11+pca_data$PC12+pca_data$PC13+pca_data$PC14, \n",
    "data=snp_data, \n",
    "model=\"co\", \n",
    "genotypingRate=5)\n",
    "\n",
    "saveRDS(wg, \"wg_%s_co.rds\")\n",
    "stats = WGstats(wg)\n",
    "saveRDS(stats, \"wgstats_%s.rds\")\n",
    "''' % (input_file, \n",
    "       num_pca_axes,\n",
    "       num_pca_axes-1,\n",
    "       p, \n",
    "       p.lower(), \n",
    "       p.lower())\n",
    "        \n",
    "            o.write(text)\n",
    "    return out_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_snpassoc_file(trait_snpassoc_pca, \"snpassoc.txt\", 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Run this in R\n",
    "```R\n",
    "source(\"snpassoc_<trait>.R\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "wg_trait_co.rds = readRDS('wg_sucrose_co.rds')\n",
    "wgstats_trait.rds = readRDS('wgstats_sucrose.rds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wgstats_trait = r['wgstats_trait.rds']\n",
    "wgstats_trait_labels = r('labels(wg_trait_co.rds)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wgstats = {trait_name:[wgstats_trait, wgstats_trait_labels.rx2(1)]}\n",
    "for key, datalist in wgstats.items():\n",
    "    print \"converting %s\" % key\n",
    "    wgstats[key] = [com.convert_robj(x) for x in datalist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_alleles(data):\n",
    "    a = set()\n",
    "    for x in data.index:\n",
    "        for elem in x.split(\"/\"):\n",
    "            a.add(elem)\n",
    "    return list(a)  \n",
    "\n",
    "def get_allele_freqs_wg(data, AA, Aa, aa):\n",
    "    total = np.sum(data['n'])*2\n",
    "    A = data.ix[AA, \"n\"]*2 + data.ix[Aa, \"n\"]\n",
    "    a = data.ix[aa, \"n\"]*2 + data.ix[Aa, \"n\"]\n",
    "    return A/total, a/total\n",
    "\n",
    "def get_genotypes(data, alleles):\n",
    "    homos = [\"%s/%s\" % (x,x) for x in alleles]\n",
    "    Aa = \"%s/%s\" % (alleles[0], alleles[1])\n",
    "    if Aa not in data.index:\n",
    "        Aa = Aa[::-1] #reverse it\n",
    "    AA, aa = homos\n",
    "    if data.ix[AA, \"n\"] < data.ix[aa, \"n\"]:\n",
    "        AA, aa = homos[::-1] #reverse it so that major is first\n",
    "    return AA, Aa, aa\n",
    "\n",
    "def get_genotypic_values(data, alleles):\n",
    "    AA, Aa, aa = get_genotypes(data, alleles)\n",
    "    G_AA = float(data.ix[AA, 'me'])\n",
    "    G_aa = float(data.ix[aa, 'me'])\n",
    "    additive = (G_AA-G_aa)/2\n",
    "    G_Aa = float(data.ix[Aa, 'me'])\n",
    "    dominance = G_Aa - ((G_AA+G_aa)/2)\n",
    "    return additive, dominance, AA, Aa, aa\n",
    "    \n",
    "def get_alpha(data):\n",
    "    alleles = get_alleles(data)\n",
    "    additive, dominance, AA, Aa, aa = get_genotypic_values(data, alleles)\n",
    "    p, q = get_allele_freqs_wg(data, AA, Aa, aa)\n",
    "    alpha = additive + (dominance*(q-p))\n",
    "    return alpha, AA, aa, p, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_vals = {}\n",
    "for p in wgstats:\n",
    "    print \"running %s\" % p\n",
    "    df = pd.DataFrame(index=[\"alpha\", \"p-value\", \"AA\", \"aa\", \"p\", \"q\"])\n",
    "    alpha_vals[p] = df\n",
    "    d = wgstats[p][0]\n",
    "    labels = wgstats[p][1]\n",
    "    for i, locus in enumerate(d):\n",
    "        try:\n",
    "            data = pd.DataFrame(d[locus])\n",
    "            snp = labels[i]\n",
    "            genotypes = [g for g in data.index if \"/\" in g]\n",
    "            data = data.ix[genotypes,:]\n",
    "            pvalue = data['p-value'].dropna()[0]\n",
    "            if len(genotypes) == 3:\n",
    "                alpha, AA, aa, p, q = get_alpha(data)\n",
    "                df[snp] = [alpha, pvalue, AA, aa, p, q]\n",
    "        except Exception as e: \n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_vals[trait_name].ix[:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(alpha_vals[trait_name].ix['p-value',:], bins=30)\n",
    "plt.title(\"p-values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(alpha_vals[trait_name].ix['alpha',:], bins=30)\n",
    "plt.title(\"alpha values $\\mu %.4f \\pm %.4f \\ [%.4f, %.4f]$\" % (np.mean(alpha_vals[trait_name].ix['alpha',:]),\n",
    "                                                            np.std(alpha_vals[trait_name].ix['alpha',:]),\n",
    "                                                            np.min(alpha_vals[trait_name].ix['alpha',:]),\n",
    "                                                             np.max(alpha_vals[trait_name].ix['alpha',:])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trait_snpassoc_pca_county = pd.concat([loc_hierf.countyid, trait_snpassoc_pca], axis=1)\n",
    "trait_snpassoc_pca_county = trait_snpassoc_pca_county.drop(trait_snpassoc_pca_county[np.isnan(trait_snpassoc_pca_county[trait_name])].index)\n",
    "trait_snpassoc_pca_county[0:5]\n",
    "snpassoc_af = trait_snpassoc_pca_county.ix[:,2:-14].apply(get_allele_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_allele_freqs = {}\n",
    "for pop,data in trait_snpassoc_pca_county.groupby(\"countyid\"):\n",
    "    print \"getting allele freqs for pop % d\" % pop\n",
    "    pop_allele_freqs[pop] = data.ix[:,2:-14].apply(get_allele_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_gwas_data_file(df, pheno, outdir):\n",
    "    out = \"%s_gwas_data_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    df = df.sort_index()\n",
    "    df[['A1', 'A2', 'EFF', 'FRQ']].to_csv(out,\n",
    "                                          header=True, \n",
    "                                          index=True,\n",
    "                                          sep=\"\\t\")\n",
    "    print out\n",
    "    return out\n",
    "\n",
    "def write_freqs_file(df, pheno, pop_freqs, outdir):\n",
    "    out = \"%s_freqs_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print out\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"SNP\\tCLST\\tA1\\tA2\\tFRQ\\n\")\n",
    "        for pop, data in pop_freqs.items():\n",
    "            m = data.T.merge(df, how=\"inner\", left_index=True, right_index=True)\n",
    "            m['population'] = pop\n",
    "            m.index.name = 'SNP'\n",
    "            m = m.sort_index()\n",
    "            o.write(m[['population','A1','A2','p']].to_csv(header=False, \n",
    "                                                             index=True,\n",
    "                                                             sep=\"\\t\"))\n",
    "def write_match_pop_file(df, pheno, pop_freqs, pop, outdir):\n",
    "    out = \"%s_match_pop_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print out\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"SNP\\tCLST\\tA1\\tA2\\tFRQ\\n\")\n",
    "        for key, data in pop_freqs.items():\n",
    "            if key == pop:\n",
    "                m = data.T.merge(df, how=\"inner\", left_index=True, right_index=True)\n",
    "                m['population'] = pop\n",
    "                m.index.name = 'SNP'\n",
    "                m = m.sort_index()\n",
    "                o.write(m[['population','A1','A2','p']].to_csv(header=False, \n",
    "                                                                 index=True,\n",
    "                                                                 sep=\"\\t\"))\n",
    "                break\n",
    "                \n",
    "def write_full_dataset_file(df, pheno, pop_freqs, outdir):\n",
    "    out = \"%s_full_dataset_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print out\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"SNP\\tCLST\\tA1\\tA2\\tFRQ\\n\")\n",
    "        for pop, data in pop_freqs.items():\n",
    "            m = data.T.merge(df, how=\"inner\", left_index=True, right_index=True)\n",
    "            m['population'] = pop\n",
    "            m.index.name = 'SNP'\n",
    "            m = m.sort_index()\n",
    "            o.write(m[['population','A1','A2','p']].to_csv(header=False, \n",
    "                                                             index=True,\n",
    "                                                             sep=\"\\t\"))   \n",
    "def write_env_var_data_file(pheno, pop_freqs, outdir):\n",
    "    out = \"%s_env_var_data_file.txt\" % pheno\n",
    "    out = os.path.join(outdir, out)\n",
    "    print out\n",
    "    with open(out, \"w\") as o:\n",
    "        o.write(\"CLST\\tENV\\tREG\\n\")\n",
    "        pop_id = 0\n",
    "        for pop in pop_freqs:\n",
    "            pop_id += 1\n",
    "            o.write(\"%s\\t%f\\t%d\\n\" % (pop, np.random.randn(), pop_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "squat_outdir = \"squat_cfried\" #change for your username\n",
    "if not os.path.exists(squat_outdir):\n",
    "    os.mkdir(squat_outdir)\n",
    "\n",
    "for p in alpha_vals:\n",
    "    full = alpha_vals[p].T\n",
    "    full.index = [x.replace(\".\", \"-\") for x in full.index]\n",
    "    full.index = [x[1:] if x.startswith(\"X\") else x for x in full.index]\n",
    "    full.index.name = \"SNP\"\n",
    "    full.AA = full.AA.apply(lambda x: x[0])\n",
    "    full.aa = full.aa.apply(lambda x: x[0])\n",
    "    full = full.rename(columns={'alpha':'EFF',\n",
    "                                'AA':'A1',\n",
    "                                'aa':'A2',\n",
    "                                'p': 'FRQ'})\n",
    "    candidates = full[full['p-value']<0.001]\n",
    "    write_gwas_data_file(candidates, p, squat_outdir)\n",
    "    write_freqs_file(candidates, p, pop_allele_freqs, squat_outdir)\n",
    "    write_match_pop_file(full, p, pop_allele_freqs, 2, squat_outdir)\n",
    "    write_full_dataset_file(full, p, pop_allele_freqs, squat_outdir)\n",
    "    write_env_var_data_file(p, pop_allele_freqs, squat_outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "squat_scripts_dir = \"/gdc_home4/cfried/src/PolygenicAdaptationCode/Scripts\"\n",
    "!rm {squat_outdir}/Scripts && ln -s {squat_scripts_dir} {squat_outdir}/Scripts\n",
    "def get_squat_vars(pheno):\n",
    "    d = {\"gwas.data.file\":\"'%s_gwas_data_file.txt'\" % pheno,\n",
    "         \"freqs.file\":\"'%s_freqs_file.txt'\" % pheno,\n",
    "         \"env.var.data.files\":\"list('%s_env_var_data_file.txt')\" % pheno,\n",
    "         \"match.pop.file\":\"'%s_match_pop_file.txt'\" % pheno,\n",
    "         \"full.dataset.file\":\"'%s_full_dataset_file.txt'\" % pheno,\n",
    "         \"path\":\"'%s'\" % pheno,\n",
    "         \"match.categories\":\"c('MAF')\",\n",
    "         \"match.bins\":\"list(seq(0,0.5,0.02), c(2), seq(0,1000,100))\",\n",
    "         \"cov.SNPs.per.cycle\":5000,\n",
    "         \"cov.cycles\":1,\n",
    "         \"null.phenos.per.cycle\":1000,\n",
    "         \"null.cycles\":1,\n",
    "         \"load.cov.mat\":\"F\",\n",
    "         \"sim.null\":\"T\",\n",
    "         \"check.allele.orientation\":\"F\"}\n",
    "    return ',\\n'.join(\"%s=%s\" % (key,val) for (key,val) in d.items())\n",
    "\n",
    "def create_squat_run_file(pheno):\n",
    "    squat_file = os.path.join(squat_outdir, \"squat_%s.r\" % pheno)\n",
    "    with open(squat_file, \"w\") as o:\n",
    "        o.write('system(\"rm -rf %s\")\\n'% pheno)\n",
    "        o.write(\"source('%s')\\n\" % os.path.join(squat_scripts_dir, \"CreateTraitFile.R\"))\n",
    "        o.write(\"source('%s')\\n\" % os.path.join(squat_scripts_dir, \"functions.R\"))\n",
    "        o.write(\"PolygenicAdaptationFunction(%s)\\n\" % get_squat_vars(pheno))\n",
    "    return squat_file\n",
    "\n",
    "for pheno in alpha_vals:\n",
    "    squat_file = create_squat_run_file(pheno)\n",
    "    print squat_file\n",
    "    !cat $squat_file\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_squat(p):\n",
    "    print \"running %s\" % p\n",
    "    output = \"%s/%s\" % (squat_outdir, p)\n",
    "    if os.path.exists(output):\n",
    "        !rm -rf {output}\n",
    "    cmds = [\"setwd('%s')\" % squat_outdir,\n",
    "            'source(\"squat_%s.r\")' % (p),\n",
    "            \"setwd('../')\"]\n",
    "    for cmd in cmds:\n",
    "        print cmd\n",
    "        r(cmd)\n",
    "    \n",
    "run_squat(trait_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfiles = !find {squat_outdir} | grep Robj | grep Output | grep {trait_name}\n",
    "bc = {}\n",
    "for f in rfiles:\n",
    "    d = f.split(\"/\")\n",
    "    if not d[1] in bc:\n",
    "        bc[d[1]] = []\n",
    "    bc[d[1]].append(f)\n",
    "bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for pheno in bc:\n",
    "    print pheno\n",
    "    for obj in bc[pheno]:\n",
    "        r('load(\"%s\")' % obj)\n",
    "    print r(\"the.stats\")\n",
    "    print(\"------------------\")\n",
    "    print r(\"p.vals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Bayenv\n",
    "\n",
    "##Setup Bayenv input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_df['county_state'] = bayenv_df.apply(lambda row: \"%s_%s\" % (row.county, row.state), axis=1)\n",
    "bayenv_df = bayenv_df.drop(drop.index)\n",
    "bayenv_df['countyid'] = bayenv_df.apply(lambda row: county_id[row.county_state], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bayenv_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayenv_dir = \"bayenv\"\n",
    "snp_names = [x for x in bayenv_df.columns if \"-\" in x]\n",
    "popids = sorted(trait_snpassoc.countyid.unique())\n",
    "\n",
    "if not os.path.exists(bayenv_dir):\n",
    "    os.mkdir(bayenv_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bayenv_snp(snp_name, popids):\n",
    "    P = []\n",
    "    Q = []\n",
    "    for popid in popids:\n",
    "        P.append(pop_allele_freqs[popid].ix[\"P\",name])\n",
    "        Q.append(pop_allele_freqs[popid].ix[\"Q\",name])\n",
    "    return P, Q\n",
    "\n",
    "def write_bayenv_snp(fh_snp, fh_names, name, P, Q):\n",
    "    if sum(Q) > 0: #exclude monomorphic loci\n",
    "        if fh_names:\n",
    "            fh_names.write(\"%s\\n\" % name)\n",
    "        P = [str(x) for x in P]\n",
    "        Q = [str(x) for x in Q]\n",
    "        fh_snp.write(\"%s\\t\\n\" % \"\\t\".join(Q))\n",
    "        fh_snp.write(\"%s\\t\\n\" % \"\\t\".join(P))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"bayenv.txt\", \"w\") as o:\n",
    "    with open(\"bayenv_names.txt\", \"w\") as n:\n",
    "        for name in snp_names:\n",
    "            P,Q = get_bayenv_snp(name, popids)\n",
    "            write_bayenv_snp(o, n, name, P, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cp bayenv.txt {bayenv_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head bayenv.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!head bayenv_names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(popids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Run Bayenv to create variance-covariance matrix\n",
    "\n",
    "```bash\n",
    "    cd bayenv && /gdc_home4/cfried/src/bayenv2/bayenv2 -i bayenv.txt -p 30 -k 100000 -r 63479 > matrix.out\n",
    "```\n",
    "\n",
    "* -p number of populations (`len(popids)`)\n",
    "* -k mcmc generations\n",
    "* -r random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Run Bayenv mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_ai['county_state'] = data_ai.apply(lambda row: \"%s_%s\" % (row.County, row.State), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_df_ai = bayenv_df.merge(data_ai, on='county_state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_df_ai[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayenv_df_ai.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_bayenv_env(data):\n",
    "    E = pd.Series()\n",
    "    for col in data.columns[:-1]:\n",
    "        E[col] = data[col].values[0]\n",
    "    return E\n",
    "\n",
    "ai_cols = [x for x in bayenv_df_ai if 'AI_' in x]\n",
    "ai_cols.append('countyid')\n",
    "bayenv_df_ai_groups = bayenv_df_ai.ix[:,ai_cols].groupby(\"countyid\")\n",
    "env_ai = []\n",
    "for popid in popids:\n",
    "    env_ai.append(get_bayenv_env(bayenv_df_ai_groups.get_group(popid))) \n",
    "env_ai_df = pd.DataFrame(env_ai).T\n",
    "env_ai_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env_ai_df = env_ai_df.apply(preprocessing.scale, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env_ai_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env_ai_df.apply(np.mean, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"%s/envmatrix.txt\" % bayenv_dir, \"w\") as o:\n",
    "    for row in env_ai_df.iterrows():\n",
    "        vals = \"\\t\".join([str(x) for x in row[1].values])\n",
    "        o.write(\"%s\\t\\n\" % vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!tail -n 13 bayenv/matrix.out > bayenv/matrix_last.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def setup_bayenv_cmd(snpfile, name):\n",
    "    work_dir = \"/gdc_home4/cfried/ipython/bayenv\"\n",
    "    bayenv = \"/gdc_home4/cfried/src/bayenv2/bayenv2\"\n",
    "    bayenv_matrix = \"matrix_last.out\"\n",
    "    bayenv_seed = -47372\n",
    "    bayenv_pops = 12\n",
    "    bayenv_runs = 100000\n",
    "    bayenv_environs = 4\n",
    "    bayenv_envmatrix = \"envmatrix.txt\"\n",
    "    bayenv_cmd = \"cd %s/%s && %s -i %s -m %s -e %s -p %d -k %d -n %d -t -c -f -o %s\" % (work_dir, \n",
    "                                                                                        name,\n",
    "                                                                                        bayenv,\n",
    "                                                                         snpfile,\n",
    "                                                                         bayenv_matrix,\n",
    "                                                                         bayenv_envmatrix,\n",
    "                                                                         bayenv_pops,\n",
    "                                                                     bayenv_runs,\n",
    "                                                                     bayenv_environs,\n",
    "                                                                             snpfile)\n",
    "    shutil.copy(bayenv_matrix, os.path.join(work_dir, name))\n",
    "    shutil.copy(bayenv_envmatrix, os.path.join(work_dir, name))\n",
    "    return bayenv_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmds = []\n",
    "if not os.path.exists(bayenv_dir):\n",
    "    os.mkdir(bayenv_dir)\n",
    "\n",
    "for name in snp_names:\n",
    "    P,Q = get_bayenv_snp(name,popids)\n",
    "    if sum(Q) > 0:\n",
    "        file_dir = os.path.join(bayenv_dir, name)\n",
    "        \n",
    "        if os.path.exists(file_dir):\n",
    "            shutil.rmtree(file_dir)\n",
    "        \n",
    "        if not os.path.exists(file_dir):\n",
    "            os.mkdir(file_dir)\n",
    "        o = open(os.path.join(file_dir, \"%s.txt\" % name), \"w\")\n",
    "        write_bayenv_snp(o, None, name, P, Q)\n",
    "        o.close()\n",
    "        cmd = setup_bayenv_cmd(os.path.basename(o.name), name)\n",
    "        cmds.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print cmds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc = Client(profile=\"gdcsrv2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dview = rc[:]\n",
    "lview = rc.load_balanced_view()\n",
    "len(lview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_hostname():\n",
    "    import socket\n",
    "    return socket.gethostname()\n",
    "dview['get_hostname'] = get_hostname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dview.scatter(\"cpu\", range(len(rc)), flatten=True)\n",
    "def run_cmd(cmd):\n",
    "    import stopwatch\n",
    "    from subprocess import Popen, PIPE\n",
    "    import psutil\n",
    "    import multiprocessing\n",
    "    t = stopwatch.Timer()\n",
    "    p = Popen(cmd, shell=True, stdout=PIPE, stderr=PIPE)\n",
    "    proc = psutil.Process(p.pid)\n",
    "    proc.set_cpu_affinity([cpu])\n",
    "    print \"affinity is %s\" % proc.get_cpu_affinity() \n",
    "    stdout, stderr = p.communicate()\n",
    "    t.stop()\n",
    "    return cmd, stdout, stderr, str(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dview['run_cmd'] = run_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "import psutil\n",
    "import os\n",
    "import multiprocessing\n",
    "p = psutil.Process(os.getpid())\n",
    "p.set_cpu_affinity([cpu])\n",
    "#p.set_cpu_affinity(range(multiprocessing.cpu_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#bayenv_jobs = lview.map_async(run_cmd, cmds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bayenv_jobs.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bf_files = !find bayenv | grep bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf_data = {}\n",
    "for b in bf_files:\n",
    "    d = open(b).readlines()\n",
    "    d = d[-1].strip().split(\"\\t\")[1:]\n",
    "    if len(d) == 12:\n",
    "        bf_data[os.path.basename(b).replace(\".txt.bf\",\"\")] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bf = pd.DataFrame(bf_data).T.astype(float)\n",
    "bf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_files = !find bayenv | grep freqs\n",
    "freq_data = {}\n",
    "for f in freq_files:\n",
    "    d = open(f).readline().strip().split()\n",
    "    if len(d) ==  12:\n",
    "        freq_data[os.path.basename(f).replace(\".txt.freqs\",\"\")] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_df = pd.DataFrame(freq_data).T\n",
    "freq_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_df.to_csv(\"bayenv_freqs.txt\", header=True, index=True, sep=\"\\t\")\n",
    "bf.to_csv(\"bayenv_bf.txt\", header=True, index=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FileLink(\"bayenv_bf.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FileLink(\"bayenv_freqs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(bf.ix[:,1], bf.ix[:,2])\n",
    "plt.xlabel(\"Spearman\")\n",
    "plt.ylabel(\"Pearson\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(bf.ix[:,1], bf.ix[:,0])\n",
    "plt.xlabel(\"Spearman\")\n",
    "plt.ylabel(\"Bayes factor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_outliers(df, key, num_std):\n",
    "    if key == \"bf\":\n",
    "        key = 0\n",
    "    elif key == \"rho\":\n",
    "        key = 1  \n",
    "    outliers = {}   \n",
    "    ai = 0\n",
    "    for i in xrange(key, len(df.columns), 3):\n",
    "        d = df.ix[:,i]\n",
    "        d_std = np.std(d)\n",
    "        d_mean = np.mean(d)\n",
    "        cutoffs = [d_mean + (num_std*d_std), d_mean - (num_std*d_std)]\n",
    "        env = ai_cols[ai]\n",
    "        outliers[env] = d[(d >= cutoffs[0]) | (d <= cutoffs[1])]\n",
    "        ai += 1\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_outliers(df, key, num_std):\n",
    "    if key == \"bf\":\n",
    "        key = 0\n",
    "    elif key == \"rho\":\n",
    "        key = 1   \n",
    "    ai = 0\n",
    "    for i in xrange(key, len(df.columns), 3):\n",
    "        d = df.ix[:,i]\n",
    "        d_std = np.std(d)\n",
    "        d_mean = np.mean(d)\n",
    "        env = ai_cols[ai]\n",
    "        ax = plt.gca()\n",
    "        if key == 0:\n",
    "            ax.set_yscale('log')\n",
    "        plt.hist(d, bins=100)\n",
    "        plt.xlim(np.min(d), d_mean+(num_std*d_std))\n",
    "        plt.title(\"%s $\\mu = %.4f \\pm %.4f [%.4f, %.4f])$\" % (env,\n",
    "                                                            d_mean,\n",
    "                                                            d_std,\n",
    "                                                            np.min(d),\n",
    "                                                            np.max(d)))\n",
    "        plt.show()\n",
    "        ai += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_outliers(bf, \"bf\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_outliers(bf, \"rho\", 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf_outliers = get_outliers(bf, \"bf\", 6)    \n",
    "rho_outliers = get_outliers(bf, \"rho\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bf_outliers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rho_outliers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(VennDiagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def draw_venn(outliers, title):\n",
    "    keys = sorted(list(outliers.keys()))\n",
    "    a1 = set(outliers[keys[0]].index)\n",
    "    a2 = set(outliers[keys[1]].index)\n",
    "    a3 = set(outliers[keys[2]].index)\n",
    "    a4 = set(outliers[keys[3]].index)\n",
    "    area1 = len(a1)\n",
    "    area2 = len(a2)\n",
    "    area3 = len(a3) \n",
    "    area4 = len(a4)\n",
    "    n12 = len(a1.intersection(a2))\n",
    "    n13 = len(a1.intersection(a3))\n",
    "    n14 = len(a1.intersection(a4))\n",
    "    n23 = len(a2.intersection(a3))\n",
    "    n24 = len(a2.intersection(a4))\n",
    "    n34 = len(a3.intersection(a4))\n",
    "    n123 = len(set.intersection(a1, a2, a3))\n",
    "    n124 = len(set.intersection(a1, a2, a4))\n",
    "    n134 = len(set.intersection(a1, a3, a4))\n",
    "    n234 = len(set.intersection(a2, a3, a4))\n",
    "    n1234 = len(set.intersection(a1, a2, a3, a4))\n",
    "    venn = \"venn_%s.png\" % title.replace(\" \", \"_\")\n",
    "    r(\"library(VennDiagram)\")\n",
    "    r(\"png('%s')\" % venn)\n",
    "    r('draw.quad.venn')(area1, \n",
    "                  area2,\n",
    "                  area3,\n",
    "                  area4,\n",
    "                  n12,\n",
    "                  n13,\n",
    "                  n14,\n",
    "                  n23,\n",
    "                  n24,\n",
    "                  n34,\n",
    "                  n123,\n",
    "                  n124,\n",
    "                  n134,\n",
    "                  n234,\n",
    "                  n1234,\n",
    "                       category=keys)\n",
    "    r('dev.off()')\n",
    "    return venn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(draw_venn(bf_outliers, \"Bayes factor outliers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(draw_venn(rho_outliers, \"Rho outliers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_outliers = {}\n",
    "for key in bf_outliers:\n",
    "    a = bf_outliers[key].index\n",
    "    b = rho_outliers[key].index\n",
    "    combined_outliers[key] = pd.Series(index=a.intersection(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(draw_venn(combined_outliers, \"combined\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxplot_data = {}\n",
    "for key, val in bf_outliers.items():\n",
    "    val = val.sort(inplace=False, ascending=False)\n",
    "    boxplot_data[key] = {val.index[0]: val[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boxplot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bayenv_df_ai_basegt = bayenv_df_ai.apply(convert_to_snpassoc)\n",
    "for env in boxplot_data:\n",
    "    for snp in boxplot_data[env]:\n",
    "        vals = {}\n",
    "        for gt, group in bayenv_df_ai_basegt.groupby(snp):\n",
    "            if not gt == 'NA':\n",
    "                vals[gt.replace(\"/\", \"\")] = group[env]\n",
    "        vals = pd.DataFrame(vals, dtype=float)\n",
    "        vals.index.name = env\n",
    "\n",
    "        sns.boxplot([vals[x].dropna() for x in vals], \n",
    "                    names=vals.columns)\n",
    "        plt.title(\"%s/%s (%.4f)\" % (snp, vals.index.name, boxplot_data[env][snp]))\n",
    "        plt.show()\n",
    "\n",
    "        sns.violinplot([vals[x].dropna() for x in vals], \n",
    "                    names=vals.columns)\n",
    "        plt.title(\"%s/%s (%.4f)\" % (snp, vals.index.name, boxplot_data[env][snp]))\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "gist_id": "22fbfd482f95d12701f7",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}