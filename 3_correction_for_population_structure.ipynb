{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Exploring Patterns of Population Structure and Environmental Associations to Aridity Across the Range of Loblolly Pine\n",
    "\n",
    "##Introduction\n",
    "\n",
    "In this set of analyses, we will be making use of data from the Eckert et al. 2010 paper to explore patterns of phenotypic and environmental associations among populations of loblolly pine.\n",
    "\n",
    "\n",
    "###Abstract\n",
    "\n",
    "Natural populations of forest trees exhibit striking phenotypic adaptations to diverse environmental\n",
    "gradients, thereby making them appealing subjects for the study of genes underlying ecologically relevant phenotypes. Here, we use a genome-wide data set of single nucleotide polymorphisms genotyped across 3059 functional genes to study patterns of population structure and identify loci associated with aridity across the natural range of loblolly pine (Pinus taeda L.). Overall patterns of population structure, as inferred using principal components and Bayesian cluster analyses, were consistent with three genetic clusters likely resulting from expansions out of Pleistocene refugia located in Mexico and Florida. A novel application of association analysis, which removes the confounding effects of shared ancestry on correlations between genetic and environmental variation, identified five loci correlated with aridity. These loci were primarily involved with abiotic stress response to temperature and drought. A unique set of 24 loci was identified as FST outliers on the basis of the genetic clusters identified previously and after accounting for expansions out of Pleistocene refugia. These loci were involved with a diversity of physiological processes. Identification of nonoverlapping sets of loci highlights the fundamental differences implicit in the use of either method and suggests a pluralistic, yet complementary, approach to the identification of genes underlying ecologically relevant phenotypes.\n",
    "\n",
    "\n",
    "##Overview of tasks\n",
    "\n",
    "In general, what you will be doing is working your way from loading and saving data related to this study, to corrections for population structure, to looking for associations between genotypes and phenotypes, genotypes and the environment (`Bayenv2`), and genotypes+phenotypes+environment (`SQUAT`)\n",
    "\n",
    "## This notebook\n",
    "\n",
    "This notebook will walk you through getting SNP and phenotype associations, while correcting for population structure.  You will.\n",
    "\n",
    "1. Remove the effect of population structure on the phenotype\n",
    "1. Remove the effect of population structure on the genotype\n",
    "1. Perform genotype-phenotype correlations for each SNP\n",
    "1. Correct for multiple tests\n",
    "1. Explore the full Patterson method (leave-one-out)\n",
    "\n",
    "As with the previous notebook, execute the cell with the imports and continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import rpy2\n",
    "from rpy2 import robjects as ro\n",
    "import pandas.rpy.common as com\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import operator\n",
    "import scipy as sp\n",
    "import traceback\n",
    "from sklearn import preprocessing\n",
    "from IPython.parallel import Client\n",
    "from subprocess import Popen, PIPE\n",
    "import shutil\n",
    "from IPython.display import FileLink, FileLinks, Image\n",
    "import psutil\n",
    "import multiprocessing\n",
    "from hdfstorehelper import HDFStoreHelper\n",
    "import warnings\n",
    "import pandas\n",
    "import dill\n",
    "import statsmodels as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats.stats import pearsonr\n",
    "warnings.simplefilter(\"ignore\", pandas.io.pytables.PerformanceWarning)\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext rpy2.ipython\n",
    "pd.set_option('display.width', 80)\n",
    "pd.set_option('max.columns', 30)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = ro.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(qvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf = HDFStoreHelper(\"data.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_drop_std = hdf.get(\"pca_drop_std\")\n",
    "pheno = hdf.get(\"pheno\")\n",
    "pca_cov = hdf.get(\"pca_cov\")\n",
    "trait_complete = hdf.get(\"trait_complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait_complete_pca = trait_complete.join(pca_cov, how=\"inner\").merge(pca_drop_std, \n",
    "                                                left_index=True, \n",
    "                                                right_index=True,\n",
    "                                               suffixes = ('_hierf','_pca'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait_complete_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait_name = str(dill.load(open(\"trait_name.dill\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_cols = [x for x in trait_complete_pca if 'PC' in x]\n",
    "pca_cols\n",
    "pca_cov_string = \"+\".join(pca_cols)\n",
    "pca_cov_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Did you know that you can do linear regression in Python?  \n",
    "\n",
    "Well, there's that plus much, much more.  Ready to abandon `R` yet?\n",
    "\n",
    "The cell below runs a linear regression between the phenotype data with the PCA axes as covariates.  After you run the fit, check out the summary.  Notice anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"%s~%s\" % (trait_name, pca_cov_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_fit = smf.ols(formula=\"%s~%s\" % (trait_name, pca_cov_string), \n",
    "                data=trait_complete_pca).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_fit.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Because we have to use this data in `R` later, let's make it friendly by fixing \"-\" and the fact that some SNPs start with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trait_complete_pca.columns = [x.replace(\"-\", \"_\") if '_pca' in x else x for x in trait_complete_pca.columns]\n",
    "trait_complete_pca.columns = [\"X%s\" % x if '_pca' in x else x for x in trait_complete_pca.columns]\n",
    "trait_complete_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put(\"trait_complete_pca\", trait_complete_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Let's do those regressions\n",
    "\n",
    "1. For each SNP, remove effect of pop structure\n",
    "1. Correlate that SNPs residual's with the residuals of the phenotype\n",
    "1. Rejoice.\n",
    "\n",
    "This takes a minute or two on this data set.  If you have 100,000 SNPs in your data, go get a beer (or 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_num = 0\n",
    "snp_cor = {}\n",
    "for col in trait_complete_pca:\n",
    "    if \"_pca\" in col:\n",
    "        formula=\"%s ~ %s\" % (str(col), pca_cov_string)\n",
    "        g_fit = smf.ols(formula=formula, data=trait_complete_pca).fit()\n",
    "        corrected = pearsonr(g_fit.resid, p_fit.resid)\n",
    "        snp_cor[col] = corrected\n",
    "        snp_num += 1\n",
    "        if snp_num % 100 == 0:\n",
    "            print \"at %d\" % snp_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Let's store these so we don't have to run them later.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_cor_df = pd.DataFrame(snp_cor, index=(\"r\", \"p\")).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_cor_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####We will use the Storey and Tibshirani (2003) method to correct for multiple tests using their `R` package available in `BioConductor`, `qvalue` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_qvalues(pvalues):\n",
    "    qvalue = r(\"qvalue\")\n",
    "    qobj = qvalue(pvalues)\n",
    "    qvalues = qobj.rx2(\"qvalues\")\n",
    "    return np.array(qvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = get_qvalues(snp_cor_df.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_cor_df['q'] = q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_cor_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####We can also get a description of a column in a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snp_cor_df.q.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####This next bit of code is a bit complicated, but luckily you don't have to run it.\n",
    "\n",
    "Patterson et al. suggest computing PCAs for each SNP such that the SNP that you're testing for association is not included in the data.  Can you think about why this might be the case?  Can you imagine how long this will take for large data sets.  A data set that I did this on for the talk I gave at Evolution 2014 was on about 79,000 SNPs and across 700 CPUs it still took about 6 hours.  \n",
    "\n",
    "The code relies on IPython's parallel machinery to \n",
    "\n",
    "1. Set up a client to conenct to a cluster (after having started on)\n",
    "1. Distributing the PCA function across the cluster\n",
    "1. Running the jobs in parallel.  Caution here, if you have too many IPython engines running R processes, things sometimes crash.  No idea why.  Darn open source software.  I'm happy to talk about the code, but right now it's just here for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```python\n",
    "rc = Client(profile=\"gdcsrv2\")\n",
    "dview = rc[:]\n",
    "lview = rc.load_balanced_view()\n",
    "len(dview)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```python\n",
    "def do_pca_in_parallel(locus):\n",
    "    import os,sys\n",
    "    sys.path.append(\"/gdc_home4/cfried/ipython/\")\n",
    "    os.environ['R_HOME'] = '/gdc_home4/cfried/R3/lib64/R'\n",
    "    import rpy2.robjects as ro\n",
    "    import pandas.rpy.common as com\n",
    "    from pandas import DataFrame\n",
    "    from hdfstorehelper import HDFStoreHelper\n",
    "    hdf = HDFStoreHelper(\"/gdc_home5/groups/congenomics/day5/cfried/data.hd5\")\n",
    "    df = hdf.get(\"trait_complete_pca\")\n",
    "    r = ro.r\n",
    "    prcomp = r('prcomp')\n",
    "    df = df.ix[:,[x for x in df.columns if '_pca' in x]]\n",
    "    df = df.drop(locus, axis=1)\n",
    "    res = prcomp(com.convert_to_r_matrix(df), scale=False, center=False)\n",
    "    x = com.convert_robj(res.rx2(\"x\"))\n",
    "    x.index = df.index\n",
    "    return locus, x.ix[:,0:14].to_dict()\n",
    "\n",
    "dview['do_pca_in_parallel'] = do_pca_in_parallel\n",
    "\n",
    "pca_jobs = []\n",
    "for col in trait_complete_pca:\n",
    "    if \"_pca\" in col:\n",
    "        job = lview.apply_async(do_pca_in_parallel, col)\n",
    "        pca_jobs.append(job)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```python\n",
    "ready = 0\n",
    "pca_results = {}\n",
    "for p in pca_jobs:\n",
    "    if p.ready():\n",
    "        res = p.r\n",
    "        assert len(res) == 2\n",
    "        pca_results[res[0]] = res[1]\n",
    "        ready += 1\n",
    "print ready, len(pca_jobs)\n",
    "\n",
    "dill.dump(pca_results, open(\"pca_results.dill\", \"w\"))\n",
    "\n",
    "dill.dump(ols_results, open(\"ols_results.dill\", \"w\"))\n",
    "\n",
    "pca_results = dill.load(open(\"pca_results.dill\"))\n",
    "\n",
    "snp_num = 0\n",
    "snp_cor2 = {}\n",
    "for col in trait_complete_pca:\n",
    "    if \"_pca\" in col:\n",
    "        pca_cov2 = pd.DataFrame(pca_results[col])\n",
    "        df = trait_complete_pca.merge(pca_cov2, how=\"inner\", left_index=True,\n",
    "                                     right_index=True, suffixes=('_x','_y'))\n",
    "        pca_cov_string = \"+\".join([\"%s_y\" % x for x in pca_cov2.columns])\n",
    "        formula=\"%s ~ %s\" % (str(col), pca_cov_string)\n",
    "        \n",
    "        g_fit = smf.ols(formula=formula, data=df).fit()\n",
    "        if snp_num % 100 == 0:\n",
    "            print \"at %d\" % snp_num\n",
    "        corrected = pearsonr(g_fit.resid, p_fit.resid)\n",
    "        snp_cor2[col] = corrected\n",
    "        snp_num += 1\n",
    "        \n",
    "\n",
    "snp_cor2_df = pd.DataFrame(snp_cor2, index=['r', 'p']).T\n",
    "snp_cor2_df.head()\n",
    "cors = snp_cor_df.merge(snp_cor2_df, how=\"inner\", suffixes=['_1', '_2'], left_index=True, right_index=True)\n",
    "hdf.put(\"snp_cor_df\", snp_cor_df)\n",
    "hdf.put(\"snp_cor2_df\", snp_cor2_df)\n",
    "hdf.put(\"cors\", cors)\n",
    "        \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf2_file = \"/gdc_home5/groups/congenomics/day5/cors.hdf\"\n",
    "hdf2 = HDFStoreHelper(hdf2_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cors = hdf.get(\"cors\")\n",
    "plt.scatter(cors.r_1, cors.r_2)\n",
    "plt.xlabel(\"locus not removed\")\n",
    "plt.ylabel(\"locus removed\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q2 = get_qvalues(cors[\"p_2\"])\n",
    "cors[\"q2\"] = q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cors[cors.q < 0.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####How many SNPs are significantly correlated to your phenotype?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdf.put(\"cors\", cors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}